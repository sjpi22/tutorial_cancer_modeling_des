
> FLAGS <- flags(flag_integer("n_hidden_layers", 2), 
+     flag_integer("n_hidden_nodes", 64), flag_boolean("dropout", 
+         TRUE), flag_numeric .... [TRUNCATED] 

> input <- layer_input(shape = ncol(data_sim_param_train))

> for (i in 1:FLAGS$n_hidden_layers) {
+     if (i == 1) {
+         x <- layer_dense(input, units = FLAGS$n_hidden_nodes, 
+             activation = .... [TRUNCATED] 

> output <- list()

> loss_list <- list()

> loss_weights <- list()

> metrics_list <- list()

> for (i in df_fn_grp_chars$fn_grp) {
+     temp_df_fn_grps <- df_fn_grp_chars[df_fn_grp_chars$fn_grp == 
+         i, ]
+     output[[i]] <- layer_de .... [TRUNCATED] 

> model <- keras_model(inputs = input, outputs = output)

> summary(model)
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)          ┃ Output Shape      ┃     Param # ┃ Connected to       ┃
┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩
│ input_layer           │ (None, 13)        │           0 │ -                  │
│ (InputLayer)          │                   │             │                    │
├───────────────────────┼───────────────────┼─────────────┼────────────────────┤
│ dense (Dense)         │ (None, 64)        │         896 │ input_layer[0][0]  │
├───────────────────────┼───────────────────┼─────────────┼────────────────────┤
│ dense_1 (Dense)       │ (None, 64)        │       4,160 │ dense[0][0]        │
├───────────────────────┼───────────────────┼─────────────┼────────────────────┤
│ dense_2 (Dense)       │ (None, 16)        │       1,040 │ dense_1[0][0]      │
├───────────────────────┼───────────────────┼─────────────┼────────────────────┤
│ dense_3 (Dense)       │ (None, 3)         │         195 │ dense_1[0][0]      │
├───────────────────────┼───────────────────┼─────────────┼────────────────────┤
│ dense_4 (Dense)       │ (None, 4)         │         260 │ dense_1[0][0]      │
└───────────────────────┴───────────────────┴─────────────┴────────────────────┘
 Total params: 6,551 (25.59 KB)
 Trainable params: 6,551 (25.59 KB)
 Non-trainable params: 0 (0.00 B)

> model %>% compile(loss = loss_list, loss_weights = loss_weights, 
+     optimizer = optimizer_adam(), metrics = metrics_list)

> history <- model %>% fit(x = xtrain_scaled, y = ytrain_scaled_reshape, 
+     epochs = n_epochs, batch_size = n_batch_size, validation_split = 0.2,  .... [TRUNCATED] 
